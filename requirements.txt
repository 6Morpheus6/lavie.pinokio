accelerate
av==10.0.0
black==23.7.0
chardet==5.1.0
clip @ git+https://github.com/openai/CLIP.git
#decord==0.6.0
diffusers[torch]==0.19.3
#diffusers[torch]
#diffusers
einops>=0.6.1
fairscale>=0.4.13
ffmpeg==1.4
fire>=0.5.0
fsspec>=2023.6.0
gradio==5.0
huggingface_hub==0.25.2
imageio==2.31.1
imageio-ffmpeg==0.4.9
invisible-watermark>=0.2.0
kornia==0.6.9
matplotlib>=3.7.2
natsort==8.4.0
ninja>=1.11.1
numpy==1.26.4
#open-clip-torch>=2.20.0
omegaconf==2.3.0
open-clip-torch
opencv-python==4.6.0.66
pandas==2.0.1
pillow>=9.5.0
pudb>=2022.1.3
pydantic==2.10.6
#pytorch-lightning==2.0.1
pytorch-lightning
pyyaml>=6.0.1
rotary_embedding_torch
scipy>=1.10.1
streamlit>=0.73.1
tensorboardx==2.6
timm==0.6.13
#tokenizers==0.12.1
tokenizers
#torch>=2.0.1
#torchaudio>=2.0.2
#torchdata==0.6.1
torchdata
#torchmetrics>=1.0.1
torchmetrics
#torchvision>=0.15.2
transformers
#triton==2.0.0
tqdm==4.65.0
uuid
urllib3<1.27,>=1.25.4
wandb>=0.15.6
webdataset>=0.2.33
wheel>=0.41.0
#xformers==0.0.20
